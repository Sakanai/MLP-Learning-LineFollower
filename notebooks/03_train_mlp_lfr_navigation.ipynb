{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HOTR4ADFxEG"
      },
      "source": [
        "**KASIFIKASI OUTPUT TARGET**\n",
        "\n",
        "0.   BELOK KANAN TAJAM\n",
        "1.   BELOK KIRI TAJAM\n",
        "2.   BELOK KANAN SIKU\n",
        "3.   BELOK KIRI SIKU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWNhfy0cWMK"
      },
      "source": [
        "# Mounting to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "YxJOQ9dBlBPj",
        "outputId": "bc545eab-40f3-4203-de00-d52441614393"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/Colab Notebooks/MLP-Learning-LineFollower/data/linefollower_dataset_transformed.csv'\n",
        "\n",
        "try:\n",
        "    simulated_data = pd.read_csv(csv_file_path)\n",
        "    print(\"Data loaded successfully from CSV.\")\n",
        "    display(simulated_data.head())\n",
        "    display(simulated_data['gerakan'].value_counts())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: CSV file not found at {csv_file_path}\")\n",
        "    print(\"Please make sure the file exists and the path is correct.\")\n",
        "    simulated_data = None "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZe3M3fGcSw9"
      },
      "source": [
        "# Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFeHge0UUdmC",
        "outputId": "9406e3b9-5884-49af-e488-622a0ade48c2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)        # random data sebanyak 42 data\n",
        "from sklearn.model_selection import train_test_split     \n",
        "from tensorflow.keras.utils import to_categorical         \n",
        "\n",
        "y = simulated_data['gerakan']\n",
        "X = simulated_data.drop('gerakan', axis=1)\n",
        "\n",
        "# Convert ke numpy array\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# Train-Test Split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,       \n",
        "    random_state=42,\n",
        "    shuffle=True,   \n",
        "    stratify=y      # agar seimbang jumlahnya\n",
        ")\n",
        "\n",
        "# One-hot encoding untuk label (encoder angka 0-3 ke biner agar tidak membaca lebih dari/kurang dari)\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "print(\"Train X:\", X_train.shape)\n",
        "print(\"Train y:\", y_train_one_hot.shape)\n",
        "print(\"Test X:\", X_test.shape)\n",
        "print(\"Test y:\", y_test_one_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "8c5ce31f",
        "outputId": "34b69705-04dd-4c66-9161-2d29dc6a3fe1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(80, activation='relu', input_shape=(X.shape[1],)), \n",
        "    Dense(40, activation='relu'), \n",
        "    Dense(y_train_one_hot.shape[1], activation='softmax') # Output layer with softmax activation for multi-class classification \n",
        "])\n",
        "\n",
        "# Compile the model Adam karena lebih cepat dan adaptif dengan kondisi proses training // SGD\n",
        "# Adam = Teknik untuk memperbarui bobot saat training.\n",
        "model.compile(optimizer='adam',   \n",
        "              loss='categorical_crossentropy',      # karena di encoder ke biner, dihitung dari selisih probabilitas softmax terhadap one-hot label\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# banyaknya bias tergantung jumlah node\n",
        "# (input_features * neurons) + bias\n",
        "# (10 * 100) + 100 = 1,100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8be7dc0",
        "outputId": "79cf4be0-8da0-42f9-ebbf-62d8ff7fa2ce"
      },
      "outputs": [],
      "source": [
        "# menghentikan training otomatis saat mulai overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,                  # Jika 20 epoch berturut-turut tidak ada peningkatan val_loss → hentikan training\n",
        "    restore_best_weights=True     # Setelah training berhenti → bobot model dikembalikan ke kondisi epoch terbaik\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_one_hot),    # gunakan data test sebagai validation\n",
        "    callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "kK7E2rzSSbV8",
        "outputId": "a6f17a4b-5ded-472f-a8bd-9069f93969cb"
      },
      "outputs": [],
      "source": [
        "# BACA GRAFIK TRAINING\n",
        "# Training loss turun, validation loss turun seiring → bagus\n",
        "# Training loss terus turun, validation loss malah naik → overfitting\n",
        "# Baik training & validation loss tinggi → underfitting\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51669bf8",
        "outputId": "1b3aa62c-e8f8-4e75-fe79-343d6e4189f1"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "print(f\"Model Loss: {loss:.4f}\")\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0f6CXTwkjWw",
        "outputId": "77d4e43b-aec1-4d26-b245-3fb0a9d7d75e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "def check_dead_neurons(model, X_sample):\n",
        "    print(\"\\n Cek Neuron Mati di Setiap Layer (ReLU Layers):\")\n",
        "\n",
        "    if not model.built:\n",
        "        model.build(input_shape=(None, X.shape[1]))\n",
        "        print(\"Model built explicitly before checking dead neurons.\")\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        config = layer.get_config()\n",
        "        if 'activation' in config and config['activation'] == 'relu':\n",
        "            intermediate_model = Model(inputs=model.layers[0].input, outputs=layer.output)\n",
        "            output_values = intermediate_model.predict(X_sample, verbose=0)\n",
        "            \n",
        "            dead_mask = np.all(output_values == 0, axis=0)\n",
        "            dead_neurons = np.sum(dead_mask)\n",
        "\n",
        "            total_neurons = output_values.shape[1]\n",
        "            if total_neurons > 0:\n",
        "                persen = (dead_neurons / total_neurons) * 100\n",
        "                print(f\"Layer {i} ({layer.name}) → {dead_neurons}/{total_neurons} neuron mati ({persen:.1f}%)\")\n",
        "            else:\n",
        "                print(f\"Layer {i} ({layer.name}) → No neurons found.\")\n",
        "\n",
        "check_dead_neurons(model, X_train[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm_Mk0DYcdmg"
      },
      "source": [
        "# Ambil Bobot dan Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDqV1pQJcimT"
      },
      "outputs": [],
      "source": [
        "W1, b1 = model.layers[0].get_weights()\n",
        "W2, b2 = model.layers[1].get_weights()\n",
        "W3, b3 = model.layers[2].get_weights()\n",
        "\n",
        "np.set_printoptions(suppress=True, precision=6)\n",
        "\n",
        "# --- LAPISAN 1 (Input IR 10 ke 100 Neuron) ---\n",
        "print(f\"// --- LAPISAN 1: Bobot (W1) ---\")\n",
        "print(f\"float W1[{W1.shape[0]}][{W1.shape[1]}] = {{\")\n",
        "for row in np.round(W1, 6):\n",
        "    print(\"  {\", ', '.join(map(str, row.tolist())), \"},\")\n",
        "print(\"};\")\n",
        "\n",
        "print(f\"\\n// --- LAPISAN 1: Bias (b1) ---\")\n",
        "print(f\"float b1[{b1.shape[0]}] = {{\", ', '.join(map(str, np.round(b1, 6).tolist())), \"};\")\n",
        "\n",
        "# --- LAPISAN 2 (100 Neuron ke 50 Neuron) ---\n",
        "print(f\"\\n// --- LAPISAN 2: Bobot (W2) ---\")\n",
        "print(f\"float W2[{W2.shape[0]}][{W2.shape[1]}] = {{\")\n",
        "for row in np.round(W2, 6):\n",
        "    print(\"  {\", ', '.join(map(str, row.tolist())), \"},\")\n",
        "print(\"};\")\n",
        "\n",
        "print(f\"\\n// --- LAPISAN 2: Bias (b2) ---\")\n",
        "print(f\"float b2[{b2.shape[0]}] = {{\", ', '.join(map(str, np.round(b2, 6).tolist())), \"};\")\n",
        "\n",
        "# --- LAPISAN 3 (50 Neuron ke 4 Neuron Output) ---\n",
        "print(f\"\\n// --- LAPISAN 3: Bobot (W3) ---\")\n",
        "print(f\"float W3[{W3.shape[0]}][{W3.shape[1]}] = {{\")\n",
        "for row in np.round(W3, 6):\n",
        "    print(\"  {\", ', '.join(map(str, row.tolist())), \"},\")\n",
        "print(\"};\")\n",
        "\n",
        "print(f\"\\n// --- LAPISAN 3: Bias (b3) ---\")\n",
        "print(f\"float b3[{b3.shape[0]}] = {{\", ', '.join(map(str, np.round(b3, 6).tolist())), \"};\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8fLdNNK10IV"
      },
      "source": [
        "# Model Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWMYhxcX1zdn"
      },
      "outputs": [],
      "source": [
        "model_filename = 'model_mlp.h5'\n",
        "drive_path_model = '/content/drive/MyDrive/Colab Notebooks/MLP-Learning-LineFollower/models/'\n",
        "\n",
        "model.save(drive_path_model + model_filename)\n",
        "\n",
        "print(f\"Model MLP berhasil disimpan sebagai: {model_filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gm_Mk0DYcdmg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
